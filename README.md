# llm-hallucination-detector

A multi-agent system for detecting factual errors in AI-assisted research papers using LangGraph.

## Features
- 7 specialized agents for comprehensive verification
- LangGraph-based orchestration
- Integration with academic databases (arXiv, PubMed, Semantic Scholar)
- Confidence scoring and risk assessment

## Quick Start
```bash
git clone https://github.com/Alishba-Bacha/llm-hallucination-detector.git
cd llm-hallucination-detector
pip install -r requirements.txt
